---
title: "Compulsory Exercise 2: Prediction of Alzheimers Disease from Longitudinal MRI Data"
author:
- Chester Henry Charlton
- Kasper Eikeland
- Tinus Garshol
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes: \usepackage{amsmath}
output:
  html_document:
  #   toc: no
  #   toc_depth: '2'
  #   df_print: paged
  #pdf_document:
    toc: no
    toc_depth: '2'
urlcolor: blue
abstract: "While Alzheimer's disease is traditionally diagnosed by medical professionals, in this report we detail the use of statistical learning models to classify Alzheimer's disease. Longitudinal MRI data was used from a mix of nondemented and demented patients. This data also included several non-MRI features, such as assessments by medical professionals, education level, and the final diagnosis, which was used as a target variable for the models. The primary models tested were decision trees(?) using the random forest method, and logistic regression. Decision trees were chosen based on merit, and logistic regression was chosen for its continued use in the medical field. [sentence describing results]. While the significance of this report was lessened in ambition by the lack of data for patients who were converted from nondemented to demented, it still holds value as a way for screening patients without the assistance of a doctor, and in the more explainable models provides a way to determine the relative importance of variables in relation to Alzheimer's disease."
---

```{r setup, include=FALSE}
library("knitr")
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3,fig.align = "center")

```

```{r,eval=TRUE,echo=FALSE}
library("rmarkdown")
library("dplyr")
library("GGally")
library("tidyr")
library("formatR")
```

```{r}
setwd("/Users/chcharlton/NTNU/statLearning/tma4268_alzheimers")
# setwd("/Users/kaspe/Documents/NTNU/23V/TMA4268_Statistical_Learning/Projects/tma4268_alzheimers")
```


```{r}
longitudinal.df <- read.csv("oasis_longitudinal.csv")
# cross_sectional.df <- read.csv("oasis_cross-sectional.csv")

alzheimers.df <- read.csv("oasis_longitudinal.csv")
alzheimers.df$SES <- NULL
# mark the Group column as a factor... this can be annoying later so we need to play with it. Still need to figure out how to collide groups and make R forget about how the groups were arranged previously
# alzheimers.df$Group <-as.factor(alzheimers.df$Group)
# alzheimers.df.working <- alzheimers.df[,-c(2,)]
tail(alzheimers.df,30)
```

<!--  Henry's initial work here -->
## Henry's Stuff

NB: here is the link to the article describing this data in detail: https://direct.mit.edu/jocn/article/22/12/2677/4983/Open-Access-Series-of-Imaging-Studies-Longitudinal
how about adding some CV plots, Cp, BIC, something like that.

### Some initial EDA: 

```{r}
# select some quantitative data and plot the pairs of it
pairwise_scatter_data <- alzheimers.df[,c("Age", "EDUC", "MMSE",
                                   "eTIV", "nWBV", "ASF")]
ggpairs(data=pairwise_scatter_data)
```
```{r}
# make some box plots on CDR
par(mfrow=c(2,4))  
boxplot(Age~CDR,data=alzheimers.df)
boxplot(EDUC~CDR,data=alzheimers.df)
boxplot(MMSE~CDR,data=alzheimers.df)
boxplot(eTIV~CDR,data=alzheimers.df)
boxplot(nWBV~CDR,data=alzheimers.df)
boxplot(ASF~CDR,data=alzheimers.df)

# make some box plots on Group
par(mfrow=c(2,3))   
boxplot(Age~Group,data=alzheimers.df)
boxplot(EDUC~Group,data=alzheimers.df)
boxplot(MMSE~Group,data=alzheimers.df)
boxplot(eTIV~Group,data=alzheimers.df)
boxplot(nWBV~Group,data=alzheimers.df)
boxplot(ASF~Group,data=alzheimers.df)

```

### Goal: predict whether someone will be diagnosed with Alzheimers

Thoughts: We can only use datapoints wherein the patient is not yet demented, which means that the CDR has to be zero. So we will use the set of people who are "converted," but only the visits in which they were not yet demented. These data points will receive a target of "1." We will then include all of the "nondemented" class and set their target as "0." Our prediction goal is then to use the features to predict the target. The result of this will be a model that attempts to predict whether someone will be diagnosed with alzheimers in the future. 

```{r}
# compute deltas for relevant features on all patients
alzheimers.deltas <- 
  alzheimers.df %>%
  group_by(Subject.ID) %>% 
  arrange(.by_group = TRUE) %>% 
  summarise(dMMSE = (last(MMSE) - first(MMSE)) / last(MR.Delay),
            deTIV = (last(eTIV) - first(eTIV)) / last(MR.Delay),
            dnWBV = (last(nWBV) - first(nWBV)) / last(MR.Delay),
            dASF = (last(ASF) - first(ASF))  / last(MR.Delay))



# make deltas for converted and undemented patients, only using data for the converted patients from before they were diagnosed with alzheimer's
# -> unfortunately, this is not feasible since almost all of the converted patients have only one scan wherein they are not diagnosed
alzheimers.prediction.deltas <- 
  alzheimers.df %>%
  dplyr::filter((Group == "Converted" | Group == "Nondemented") & CDR == 0) %>% 
  group_by(Subject.ID) %>%
  arrange(.by_group = TRUE) %>% 
  summarise(dMMSE = (last(MMSE) - first(MMSE)) / last(MR.Delay),
            deTIV = (last(eTIV) - first(eTIV)) / last(MR.Delay),
            dnWBV = (last(nWBV) - first(nWBV)) / last(MR.Delay),
            dASF = (last(ASF) - first(ASF))  / last(MR.Delay))
  
# make a df of only converted and undemented patients
alzheimers.forecast <- 
  alzheimers.df %>%
  filter((Group == "Converted" | Group == "Nondemented") & Visit == 1 & CDR == 0) %>% 
  dplyr::select(-c(MRI.ID, Visit, MR.Delay, Hand, CDR))
alzheimers.forecast$Group <-as.factor(alzheimers.forecast$Group)

```

```{r}
# separate alzheimers.forecast into training and test data:
set.seed = 1337
train_indices <- sample(1:nrow(alzheimers.forecast), floor(.6 * nrow(alzheimers.forecast)))
alzheimers.forecast.train <- 
  alzheimers.forecast[train_indices,] %>% 
  na.omit() %>% 
  droplevels()
alzheimers.forecast.test <- 
  alzheimers.forecast[-train_indices,] %>% 
  na.omit() %>% 
  droplevels()
```

```{r}
# random forest tree method
set.seed = 1337
library(randomForest)

alzheimers.forecast.rf <- randomForest(Group ~., alzheimers.forecast.train, importance = TRUE)
summary(alzheimers.forecast.rf)
plot(alzheimers.forecast.rf)
predicted.rf <- predict(alzheimers.forecast.rf, newdata = alzheimers.forecast.test, type = "class")
table(predicted.rf, droplevels(alzheimers.forecast.test$Group))
```

### Result:

Unfortunately there is not enough data to make this work. With only 14 cases that changed from nondemented to demented, our data is simply too low resolution to both train and test a model well. 


## New Goal: Predict whether someone currently has alzheimers 

### Step 0: Seperate Training and Test Data: 
```{r}
set.seed = 1337
train_indices <- sample(1:nrow(alzheimers.df), floor(.6 * nrow(alzheimers.df)))
alzheimers.train <- 
  alzheimers.df[train_indices,] %>% 
  na.omit() %>% 
  droplevels()
alzheimers.test <- 
  alzheimers.df[-train_indices,] %>% 
  na.omit() %>% 
  droplevels()
```



### Step 1: Make some models
```{r}
# random forest tree method
set.seed = 1337
library(randomForest)

alzheimers.rf <- randomForest(Group ~., alzheimers.forecast.train, importance = TRUE)
summary(alzheimers.forecast.rf)
plot(alzheimers.forecast.rf)
predicted.rf <- predict(alzheimers.forecast.rf, newdata = alzheimers.forecast.test, type = "class")
table(predicted.rf, droplevels(alzheimers.forecast.test$Group))
```

```{r}
# Logistic
longitudinal.logistic <- glm(Demented ~., family = binomial, data = longitudinal.train)
logistic.probs <- predict(longitudinal.logistic, newdata = longitudinal.test, type = "response")
yhat.logistic <- ifelse(logistic.probs > .5, 1,0)
table(pred = yhat.logistic, truth = longitudinal.test$Demented) # 0.8648649
```

### Step 2: Tune and Validate methods

### Step 3: Evaluate and Compare Methods (visually and numerically)

### Step 3: Discuss




<!--  Kasper's initial work here. -->
```{r}
cross_sectional.df <- read.csv("oasis_cross-sectional.csv")


longitudinal.df <- read.csv("oasis_longitudinal.csv")

longitudinal_deltas <- longitudinal.df %>%
  group_by(Subject.ID) %>%
  summarise(dMMSE = (last(MMSE) - first(MMSE)) / last(MR.Delay),
            deTIV = (last(eTIV) - first(eTIV)) / last(MR.Delay),
            dnWBV = (last(nWBV) - first(nWBV)) / last(MR.Delay),
            dASF = (last(ASF) - first(ASF))  / last(MR.Delay),
            dAge = (last(Age) - first(Age)) / last(MR.Delay))

baseline_with_deltas <- longitudinal.df %>%
  filter(Visit == 1) %>%  
  left_join(longitudinal_deltas, by = c("Subject.ID")) %>%
  mutate(Demented = as.factor(Group != "Nondemented"), # Those who converted became demented
         M.F = as.factor(M.F)) %>%
  select(-c(Subject.ID, MRI.ID, Group, Visit, MR.Delay, Hand, CDR, SES))

# cross-sectional data
ggpairs(cs_mutated)

# longitudinal data
ggpairs(baseline_with_deltas)
```

```{r}
library("tree")
library("gbm")
library("randomForest")

set.seed(1337)
# Longitudinal data
train <- sample(1:nrow(baseline_with_deltas), floor(.75 * nrow(baseline_with_deltas)))
longitudinal.train <- na.omit(baseline_with_deltas[train,])
longitudinal.test <- na.omit(baseline_with_deltas[-train,])
```


```{r}
# Classification tree
longitudinal.tree <- tree(Demented ~., longitudinal.train)
summary(longitudinal.tree)
plot(longitudinal.tree)
text(longitudinal.tree, pretty = 0)

# Test predictions
pred.tree <- predict(longitudinal.tree, newdata=longitudinal.test, type = "class")
table(pred.tree, longitudinal.test$Demented) # 0.7837838
# Pruning?
```


```{r}
# Bagging
longitudinal.bag <- randomForest(Demented ~., longitudinal.train, mtry = 12, importance = TRUE)
summary(longitudinal.bag)
plot(longitudinal.bag)
yhat.bag <- predict(longitudinal.bag, newdata = longitudinal.test, type = "class")
table(yhat.bag, longitudinal.test$Demented) # 0.8648649
```


```{r}
# Random forest
longitudinal.rf <- randomForest(Demented ~., longitudinal.train, importance = TRUE)
summary(longitudinal.rf)
plot(longitudinal.rf)
yhat.rf <- predict(longitudinal.rf, newdata = longitudinal.test, type = "class")
table(yhat.rf, longitudinal.test$Demented) # 0.8108108
```


```{r}
# Boosting
longitudinal.train.boost <- mutate(longitudinal.train, Demented = ifelse(Demented == "FALSE", 0,1))
longitudinal.boost <- gbm(Demented ~., data = longitudinal.train.boost,
                          distribution = "bernoulli", n.trees = 1000, interaction.depth = 2)
summary(longitudinal.boost)
longitudinal.test.boost <- mutate(longitudinal.test, Demented = ifelse(Demented == "FALSE", 0,1))
yhat.boost <- predict(longitudinal.boost, newdata = longitudinal.test.boost, n.trees = 1000, type = "response")
yhat.boost <- ifelse(yhat.boost > 0.5, 1,0)
table(yhat.boost, longitudinal.test.boost$Demented)
```


```{r}
# Logistic


```


```{r}
# SVM

```


```{r}
# LDA


```


```{r}
# QDA


```


```{r}
# KNN


```


<!--  Tinus' initial work here. -->


## Introduction: Scope and purpose of your project


## Descriptive data analysis/statistics
### Description of Features:
Group: The group that the patient was classified in at the across the various scans. Possible values are "Undemented," denoting a patient without symptoms of dementia throughout all scans, "Demented" denoting a patient with symptoms of dementia accross all scans, or "Converted," denoting someone who began without symptoms of dementia but developed them at a further scan.
Visit: The order of the visit in which the scan was done, indexed from 1.
MR Delay: The number of days since the previous scan. Marked as 0 for the initial scan.
M.F: Categorical variable for male or female patients at birth. M denotes male, F denotes female.
Hand: The patient's dominant hand. All of the patients were right-handed.
EDUC: The education level of the patient, measured in years (including elementary school).
SES: "Socioeconomic status as assessed by the Hollingshead Index of Social Position and classified into categories from 1 (highest status) to 5 (lowest status) (Hollingshead, 1957)"
MMSE: "Mini-Mental State Examination score (range is from 0 = worst to 30 = best) (Folstein, Folstein, & McHugh, 1975)"
CDR: "Clinical Dementia Rating (0 = no dementia, 0.5 = very mild AD, 1 = mild AD, 2 = moderate AD) (Morris, 1993)"
ASF: "Atlas scaling factor (unitless). Computed scaling factor that transforms native-space brain and skull to the atlas target (i.e., the determinant of the transform matrix) (Buckner et al., 2004)"
eTIV: "Estimated total intracranial volume (cm3) (Buckner et al., 2004)"
nWBV: "Normalized whole-brain volume, expressed as a percent of all voxels in the atlas-masked image that are labeled as gray or white matter by the automated tissue segmentation process (Fotenos et al., 2005)"



## Methods


## Results and interpretation


## Summary
