---
title: 'Compulsory Exercise 2: Prediction of Alzheimers Disease from Longitudinal
  MRI Data'
author:
- Chester Henry Charlton
- Kasper Eikeland
- Tinus Garshol
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: no
    toc_depth: '2'
  pdf_document:
    toc: no
    toc_depth: '2'
header-includes: \usepackage{amsmath}
urlcolor: blue
abstract: "While Alzheimer's disease is traditionally diagnosed by medical professionals,
  in this report we detail the use of statistical learning models to classify Alzheimer's
  disease. Longitudinal MRI data was used from a mix of nondemented and demented patients.
  This data also included several non-MRI features, such as a short objective mental
  exam, education level, and the final diagnosis of dementia, which was used as a
  target variable for the models. The models examined were decision trees, support
  vector machines, and logistic regression. Support vector machines and decision trees
  were chosen based on applicability, and logistic regression was chosen due to its
  relevance and consistent use in the mdeical field. The selected models trained on
  a training subset of the data independently and then compared using cross-validation
  on the training data. From this the optimal model was selected, which finally was
  evaluated on the test subset of the data."
---

```{r setup, include=FALSE}
library("knitr")
knitr::opts_chunk$set(echo=TRUE, eval=TRUE, message=FALSE, warning = FALSE, 
                      strip.white = TRUE, prompt = FALSE, cache = TRUE, 
                      size = "scriptsize", fig.width = 6, fig.height = 4,
                      fig.align = "center")

```

```{r,eval=TRUE,echo=FALSE}
library("randomForest")
library("rmarkdown")
library("dplyr")
library("GGally")
library("tidyr")
library("formatR")
library('DiagrammeR')
library('bestglm')
library("pROC") 
library("cvAUC")
library('webshot')
library('boot')
```

## The block below is specific to Henry's Computer
```{r}
#specific to Henry's computer
setwd("/Users/chcharlton/NTNU/statLearning/tma4268_alzheimers")
```



## Data Processing

```{r}
# Patient is demented if CDR is > 0
longitudinal.df <- read.csv("oasis_longitudinal.csv")
longitudinal_deltas <- longitudinal.df %>% 
  group_by(Subject.ID) %>%
  summarise(dMMSE = (last(MMSE) - first(MMSE)) / last(Visit), 
            deTIV = (last(eTIV) - first(eTIV)) / last(Visit),
            dnWBV = (last(nWBV) - first(nWBV)) / last(Visit),
            dASF = (last(ASF) - first(ASF)) / last(Visit),
            dAge = (last(Age) - first(Age)) / last(Visit)) %>% 
  na.omit()
baseline_with_deltas <- longitudinal.df %>%
  filter(Visit == 1) %>%
  left_join(longitudinal_deltas, by = c("Subject.ID")) %>%
  mutate(Demented = as.factor(Group != "Nondemented"), # Those who converted became demented
         M.F = as.factor(M.F)) %>% 
  dplyr::select(-c(Subject.ID, MRI.ID, Group, Visit, MR.Delay, Hand, CDR, SES))


set.seed(1337)
# Longitudinal data
l.train.indices <- sample(1:nrow(baseline_with_deltas), floor(.75 * nrow(baseline_with_deltas)))
longitudinal.train <- na.omit(baseline_with_deltas[l.train.indices,])
longitudinal.test <- na.omit(baseline_with_deltas[-l.train.indices,])
```

## EDA: 

```{r}
# select some quantitative data and plot the pairs of it
pairwise_scatter_data <- baseline_with_deltas[,c("Age", "EDUC", "MMSE",
                                   "eTIV", "nWBV", "ASF" )]
pairwise_scatter_data.deltas <-  baseline_with_deltas[,c("dMMSE",
                                   "deTIV", "dnWBV", "dASF")]

pair_plot <- ggpairs(data=pairwise_scatter_data)
pair_plot.deltas <- ggpairs(data=pairwise_scatter_data.deltas)
```
```{r}
# boxplots 
require(reshape2)

baseline_with_deltas.m <- melt(baseline_with_deltas[-1], id.var = "Demented")

boxplots <- 
  ggplot(data = baseline_with_deltas.m, aes(x=Demented, y=value)) + 
  geom_boxplot(aes(fill=Demented)) +
  theme_minimal()
boxplots.composite <- boxplots + facet_wrap( ~ variable, ncol=4, scales = 'free_y')


```



## select optimal features
```{r}
# use AIC to select features
longitudinal.best.aic <- bestglm(longitudinal.train, family = binomial, IC = "AIC", method ="forward")
logistic.best <- longitudinal.best.aic$BestModel
# get subset table as a dataframe for future use
longitudinal.aic.subsets <- 
  longitudinal.best.aic$Subsets %>% 
  data.frame() %>% 
  cbind(variables = 1:nrow(longitudinal.best.aic$Subsets))
# make feature-AIC plot
longitudinal.aic.subsets.plot <- 
  ggplot(longitudinal.aic.subsets, aes(x = variables, y = AIC)) +
  geom_point(color = "chartreuse4", shape = "X", size = 4) +
  ggtitle("Longitudinal AIC Subset Selection") +
  labs(x = "Variables", y = "AIC") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  theme_minimal() 
```

## cv missclassification rate
```{r}
# cv.glm(longitudinal.train, logistic.best, K = 5)$delta[1]
```

## plotting the master-diagram

```{r}
masterplan <- 
mermaid("
graph TD
    start[source data]
    process[processed data]
    start --> process[processed data]
    process --> a0
    process --> a1


    a0 -->  b0 
    a0 -->  b1 
    a0 -->  b2
    a0[training data]
    a1[test data]
    b0[SVM]
    b1[Boosting]
    b2[Logistic]
    c0[subsetted SVM]
    c1[subsetted Boosting]
    
    d0[best SVM]
    d1[best Boosting]
    d2[best Logistic]
    
    e0[choose best of best models with CV]
    
    b0 --> |feat param sensitivity| c0
    b1 --> |feat param sensitivity| c1
    b2 --> |feature selection| d2
    
    c0 --> |parameter tuning| d0
    c1 --> |parameter tuning| d1
    



    a1 --> best_test
    d0 --> e0
    d1 --> e0
    d2 --> e0
    e0 --> best_test
    best_test[evaluate finaln model on test data]
    best_test --> final[interpretation]
    

    
")
```




## Introduction: Scope and purpose of your project

The goal of this project is to develop a model that can classify the diagnosis of dementia, specifically Alzheimer's.  To do this we use quantified data from MRI scans and objective psychological tests to form the basis of prediction. Data was found from Kaggle, however the original data was collated by the Open Access Series of Imaging Studies. The dataset includes MRI visits of 150 individuals between the ages of 60 and 96, providing data for several different visits of each patient to an MRI center, at which time a short psychological exam was also taken. In addition to this, the data includes a clinical diagnosis for the patient which we use as a target variable. While a simple interpretable model is desirable, our primary goal is to develop a model that can rule out some patients from further treatment, as this would reduce the load on medical professionals, particularly doctors. As such, our main focus is prediction rather than inference since we are mainly concerned with our ability to emulate the assessment of doctors on these patients. 


## Descriptive data analysis/statistics


```{r}
pair_plot

pair_plot.deltas

boxplots.composite
```




### Description of Features:

MRI.ID: The unique identifier of an MRI scan. This feature was not used. 

Group: The group that the patient was classified in the across the various scans. Possible values are "Undemented," denoting a patient without symptoms of dementia throughout all scans, "Demented" denoting a patient with symptoms of dementia across all scans, or "Converted," denoting someone who began without symptoms of dementia but developed them at a further scan. We chose to throw away "Converted," since our primary goal is to develop a classification model for patients who either have dementia or not, and the Converted class complicates this since patients in this class would fall into different categories at different times. 

Visit: The order of the visit in which the scan was done, indexed from 1. This data was not used for our model, but was used for processing the data. 

MR Delay: The number of days since the previous scan. Marked as 0 for the initial scan. Similarly, this data was not used for the model directly, but helped us for data processing as will be described later. 

M.F: Categorical variable for male or female patients at birth. M denotes male, F denotes female. This binary variable was included in the models, however feature selection points to it not being a decisive feature for classification. 

Hand: The patient's dominant hand. All of the patients were right-handed. This feature was thrown out. 

EDUC: The education level of the patient, measured in years (including elementary school). 

SES: "Socioeconomic status as assessed by the Hollingshead Index of Social Position and classified into categories from 1 (highest status) to 5 (lowest status) (Hollingshead, 1957)" 
The socioeconomic status of the patients as classified by the Hollingshead Index. Values range from 1 (most elite status) to 5 (lowest status). This feature was thrown out since it as not consistently recorded accross the patients.  

MMSE: The score of the Mini Mental State Examination. Ranges from worst (0) to best (30), and represents a measure of cognitive impairment. An example of this test is attached as an appendix. We determined from this example the that score is objective, and as such is relevant to use for an analysis where the goal is to reduce pressure on medical professionals. Due to the objective nature of the exam, it could theoretically be performed by an automated system. 

CDR: The patient's clinical dementia rating, as assessed by a medical professional. Ranges from 0 to 3, with any score above 0 representing a form of dementia. This is our target feature for classification, which we transformed into a binary variable. 

ASF: The atlas scaling factor of the patient. A measure standardizing the intra-cranial volume. 

eTIV: Estimated total intracranial volume. 

nWBV: Normalized whole-brain volume. This feature is measured as the percent of the possible total volume that is detected as grey or white matter. 


## Methods


### Data processing
The source data that we accessed had a number of peculiarities that needed to be resolved before we could use it. First and foremost, we noted that there were some features that were not feasible to use. These included Subject.ID, MRI.ID, Hand, and SES. Subject.ID is not useful to us as it is simply a unique identifier of the patient. This might have been useful if we were integrating this data into a larger context of data, but here it is not applicable. MRI.ID is similarly not useful since it is a unique identifier of the particular MRI scan. Following guidelines for tidy data, we are keeping each row as a unique observation (wide format) and so this is not necessary. Hand is a feature stating the dominant hand of the patient, and since all of the patients in this study were right-handed, it is not a valid feature to use as a predictor. SES denotes the socioeconomic status of the patient. This would have been an interesting feature to examine for predictive capacity, but it was not exhaustively collected like the other features and so many of the observations had this feature missing. Our two options given this were either to (1) throw out SES as a feature, or (2) remove observations that had this feature missing. Since such a large number of the observations were missing SES, we determined that it would be better to sacrifice it as a feature and preserve the size of our observation set. 

Beyond removing features, the next peculiarity is the longitudinal nature of the dataset, meaning that it includes multiple observations of the same individual at different points in time. The methods that we have learned in this course do not pertain to time-series data, so our solution was to add features, where relevant, that capture the basic properties of the time series information. MMSE, eTIV, nWBV, and ASF were use to create delta features (denoted as dMMSE, deTIV, etc) that represent the difference between the first and last observations of a particular feature for a particular patient, standardized with respect for time. For example, if a particular patient has their first MMSE recording stated as 28 and last as 22 with 300 days in between the measurements, their dMMSE is $\frac{28-22}{300} = 0.02$. This allows us to use the information conveyed by the longitudinal data while still using the methods from this course. 



### Model Descriptions

Logistic regression:
This method was chosen as a candidate due to its continued use in the medical field and value as a method to give classification probabilities. This is especially useful in our case since we have a binary target variable (demented or nondemented) and a combination of binary and nonbinary predictors. 
[how does it work] 
[strengths] 
[weaknesses]
[applicability for this project]
[potential limitations]
[how are we tuning this model]

Boosting decision trees:
[how does it work] 
[strengths] 
[weaknesses]
[applicability for this project]
[potential limitations]
[how are we tuning this model]

Support vector machines:
[how does it work] 
[strengths] 
[weaknesses]
[applicability for this project]
[potential limitations]
[how are we tuning this model]


### Model Selection 

Here we will provide an overview of the process we followed to arrive at a final model. 

1. Collect the source data. 

2. Process data: select relevant features, add deltas, remove time series data.  

3. Separate processed data into training and test partitions.

3. Choose a small set of hyperparameters randomly for selected models, test feature selection sensitivity to this test.

4. Once feature selection is demonstrated to be insensitive to hyperparameters, proceed with feature selection and
arbitrary hyper parameters.

5. Tune hyperparameters (as applicable)

6. Compare SVM, Boosting, and Logistic models by simulatentously testing with k-folded training data. 

7. Select best model from the three.

8. Evaluate best model on test partition. 


```{r}
masterplan
```
## Model evaluation 
[what's our loss function]
[how do we propose to compare the best models, once we have them]


## Results and interpretation

### points to discuss:

whether to include MMSE: Seems like it is objective, and only takes a few minutes to run. It could theoretically be run by existing NLP structures, so we could make an argument that using this does not compromise our goal of eliminating pressure on medical professionals. 

whether having an high specificity or sensitivity is more important: what is worse: (1) someone who truly does not have alzheimer's being told they do, or (2) someone who truly does have alzheimer's being told they don't? If (1): 


overall strategy like Kasper drew:
treat the entire process as model selection. separate test and training data. Set aside test data until we choose a final best model based on the training data.  train models on training data, setting an arbitrary set of parameters -> perform a rough sensitivity analysis for the effect of parameters on the feature selection -> choose arbitrary parameters -> perform feature selection, choosing best set of features -> tune parameters for the model with best feature set -> evaluate all three models with k-fold cv in parallel -> select best model -> 

why choose first visit as baseline instead of some other one or an average?
why only consider the change between the first and last? ]
consider adding a feature for fluctuation in other features (ie how much does eTIV fluctuate, regardless of direction)


## Summary












